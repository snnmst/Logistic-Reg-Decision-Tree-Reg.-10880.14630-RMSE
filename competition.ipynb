import pandas as pd
test_df = pd.read_csv("test_input.csv")
train_df = pd.read_csv("train.csv")

train_df['ADDCONTAMNT'].describe()

from scipy.stats import norm
# Distribution plot
def distribution_plot(data):
    sns.distplot(data, fit=norm)
    plt.ylabel('Frequency')
    plt.title(f'{data.name} distribution')
    
distribution_plot(train_df['ADDCONTAMNT'])


import matplotlib.pyplot as plt
#correlation matrix
corrmat = train_df.corr()
f, ax = plt.subplots(figsize=(12, 9))
sns.heatmap(corrmat, vmax=.8, square=True);

#missing data
total = train_df.isnull().sum().sort_values(ascending=False)
percent = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)
missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])
missing_data.head(20)

for i in range(0,12): 
    if i < 10:
        train_df = train_df.drop(train_df.loc[train_df['CONTPAIDAMNT0'+str(i)].isnull()].index)
    else:
        train_df = train_df.drop(train_df.loc[train_df['CONTPAIDAMNT'+str(i)].isnull()].index)
       
       
drop_list = ['ACCAMNTAVG03', 'ACCAMNTAVG12','ACCMVMTAVG','ACCACVNUM12', 'MAXMATEVR', 'ASTAVGDIF0312', 'CRRASTALL','LSTPRDCNUM']
for i in drop_list:
    train_df = train_df.drop(train_df.loc[train_df[i].isnull()].index)

train_df = train_df.drop(['LASTAUTOPAYTIME', 'TIMEDEPAVG12', 'BLNAMNT03','DEBTAVG00','EFTAMNTSUM12','CARDDINSUM12'], axis=1)
train_df['CONTPAIDAMNT_AVG'] = train_df[['CONTPAIDAMNT0'+str(i) if i <10 else 'CONTPAIDAMNT'+str(i) for i in range(0,12)]].sum(axis=1).astype(int)
train_df = train_df.drop(['CONTPAIDAMNT0'+str(i) if i <10 else 'CONTPAIDAMNT'+str(i) for i in range(0,12)], axis=1)

train_df.count()

train_df = train_df.drop(['TRAN_DATE'], axis = 1)

data = train_df.copy()
data.loc[data.ADDCONTAMNT > 0, 'ADDCONTAMNT'] = 1


from sklearn.model_selection import train_test_split
X = data.drop(['ADDCONTAMNT'],axis=1)
y = data.ADDCONTAMNT.values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=2)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test= sc.transform(X_test)

from sklearn.linear_model import LogisticRegression
lgr = LogisticRegression(solver='lbfgs', C=0.001)
lgr.fit(X_train,y_train)

from sklearn.metrics import mean_squared_error
y_pred = lgr.predict(X_test)
print('Test:{}'.format(np.sqrt(mean_squared_error(y_test,y_pred))))


from sklearn.model_selection import train_test_split
X1 = train_df.drop(['ADDCONTAMNT'],axis=1)
y1 = train_df.ADDCONTAMNT.values

X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.2, random_state=2)


X1_train = sc.fit_transform(X1_train)
X1_test= sc.transform(X1_test)


import numpy as np
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

dtr = DecisionTreeRegressor(max_depth=5,min_samples_split=5,min_samples_leaf=6)
#x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)
dtr.fit(X1_train,y1_train)

y_pred_dtr = dtr.predict(X1_test)
print('Test:{}'.format(np.sqrt(mean_squared_error(y1_test,y_pred_dtr))))


from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values = np.nan,strategy='mean')
imputer.fit(test_df.iloc[:,2:])
test_df.iloc[:,2:] = imputer.transform(test_df.iloc[:,2:])

test_df['CONTPAIDAMNT_AVG'] = test_df[['CONTPAIDAMNT00','CONTPAIDAMNT01','CONTPAIDAMNT02','CONTPAIDAMNT03','CONTPAIDAMNT04','CONTPAIDAMNT05','CONTPAIDAMNT06','CONTPAIDAMNT08','CONTPAIDAMNT09','CONTPAIDAMNT10','CONTPAIDAMNT11']].sum(axis=1).astype(int)
test_df = test_df.drop(['CONTPAIDAMNT00','CONTPAIDAMNT01','CONTPAIDAMNT02','CONTPAIDAMNT03','CONTPAIDAMNT04','CONTPAIDAMNT05','CONTPAIDAMNT06','CONTPAIDAMNT08','CONTPAIDAMNT09','CONTPAIDAMNT10','CONTPAIDAMNT11'],axis=1)
test_df = test_df.drop(['TRAN_DATE'], axis=1)

test_df.shape
X_train.shape

test_df = test_df.drop(['CARDDINSUM12','BLNAMNT03','DEBTAVG00','EFTAMNTSUM12', 'LASTAUTOPAYTIME', 'TIMEDEPAVG12'],axis=1)


test_df.shape
X_train.shape

X_testDF_scaled= sc.transform(test_df)

samplesub = pd.DataFrame()
samplesub['Id'] = test_df['CUSTNBR']
samplesub['Predicted'] = pd.Series(dtr.predict(X_testDF_scaled))

samplesub['ypred'] = pd.Series(lgr.predict(X_testDF_scaled))

samplesub.loc[samplesub.ypred == 0, 'Predicted'] = 0

samplesub = samplesub.drop(['ypred'],axis=1)

samplesub.to_csv('submission.csv',index=False)
